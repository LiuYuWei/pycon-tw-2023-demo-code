{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: 下載Iris Dataset"
      ],
      "metadata": {
        "id": "MQ4GkgvvDl8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N75PTEPKCl1L",
        "outputId": "ce3f09b5-dbc6-4720-d9c1-cc90185f446c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-01 09:19:40--  https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3975 (3.9K) [text/plain]\n",
            "Saving to: ‘iris.csv’\n",
            "\n",
            "iris.csv            100%[===================>]   3.88K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-09-01 09:19:41 (43.4 MB/s) - ‘iris.csv’ saved [3975/3975]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Data ETL Pipeline"
      ],
      "metadata": {
        "id": "x1Cw9NYvDvZV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PVVkfK3Ya3R0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "class DataProcessor:\n",
        "    def __init__(self, input_file):\n",
        "        \"\"\"\n",
        "        Initialize the DataProcessor class.\n",
        "\n",
        "        :param input_file: str, the path of the input csv file.\n",
        "        \"\"\"\n",
        "        self.input_file = input_file\n",
        "        self.data = None\n",
        "        self.train_data = None\n",
        "        self.test_data = None\n",
        "\n",
        "    def extract_data(self):\n",
        "        \"\"\"\n",
        "        Extract data from csv file.\n",
        "\n",
        "        :return: None\n",
        "        \"\"\"\n",
        "        self.data = pd.read_csv(self.input_file)\n",
        "\n",
        "    def transform_data(self):\n",
        "        \"\"\"\n",
        "        Transform the data by:\n",
        "        1. Filling NA values with the mean of the column.\n",
        "        2. Splitting the data into training and testing sets.\n",
        "\n",
        "        :return: None\n",
        "        \"\"\"\n",
        "        # Fill NA values with mean of the column\n",
        "        self.data.fillna(self.data.mean(), inplace=True)\n",
        "\n",
        "        # Split the data into training and testing sets\n",
        "        self.train_data, self.test_data = train_test_split(self.data, test_size=0.2)\n",
        "\n",
        "    def load_data(self, train_output_file, test_output_file):\n",
        "        \"\"\"\n",
        "        Save the transformed data to csv files.\n",
        "\n",
        "        :param train_output_file: str, the path of the training output csv file.\n",
        "        :param test_output_file: str, the path of the testing output csv file.\n",
        "        :return: None\n",
        "        \"\"\"\n",
        "        self.train_data.to_csv(train_output_file, index=False)\n",
        "        self.test_data.to_csv(test_output_file, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = 'iris.csv'\n",
        "train_output_file = 'train_output.csv'\n",
        "test_output_file = 'test_output.csv'\n",
        "data_processor = DataProcessor(input_file)\n",
        "data_processor.extract_data()\n",
        "data_processor.transform_data()\n",
        "data_processor.load_data(train_output_file, test_output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqnuCEvBCe8L",
        "outputId": "639ea14f-559c-484f-a654-64677f55cdd1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-9f5191d10bdb>:34: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  self.data.fillna(self.data.mean(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Model Training, Evaluation Pipeline"
      ],
      "metadata": {
        "id": "QQqtym4eDzx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle\n",
        "\n",
        "class Model:\n",
        "    def __init__(self, model_file='model.pkl'):\n",
        "        \"\"\"\n",
        "        Initialize the model.\n",
        "\n",
        "        Parameters:\n",
        "        model_file (str): The file to save/load the model.\n",
        "        \"\"\"\n",
        "        self.model_file = model_file\n",
        "        self.model = None\n",
        "\n",
        "    def train(self, train_data_file='train_data.csv'):\n",
        "        \"\"\"\n",
        "        Train the model using the data in the train_data_file.\n",
        "\n",
        "        Parameters:\n",
        "        train_data_file (str): The file containing the training data.\n",
        "\n",
        "        Returns:\n",
        "        None\n",
        "        \"\"\"\n",
        "        # Load the training data\n",
        "        data = pd.read_csv(train_data_file)\n",
        "        X = data.iloc[:, :-1]\n",
        "        y = data.iloc[:, -1]\n",
        "\n",
        "        # Split the data into training and validation sets\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Train the model\n",
        "        self.model = LogisticRegression(max_iter=1000)\n",
        "        self.model.fit(X_train, y_train)\n",
        "\n",
        "        # Save the model\n",
        "        with open(self.model_file, 'wb') as f:\n",
        "            pickle.dump(self.model, f)\n",
        "\n",
        "        # Evaluate the model on the validation set\n",
        "        y_pred = self.model.predict(X_val)\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "        print('Validation Accuracy:', accuracy)\n",
        "\n",
        "    def evaluate(self, test_data_file='test_data.csv'):\n",
        "        \"\"\"\n",
        "        Evaluate the model using the data in the test_data_file.\n",
        "\n",
        "        Parameters:\n",
        "        test_data_file (str): The file containing the test data.\n",
        "\n",
        "        Returns:\n",
        "        float: The accuracy of the model on the test data.\n",
        "        \"\"\"\n",
        "        # Load the test data\n",
        "        data = pd.read_csv(test_data_file)\n",
        "        X_test = data.iloc[:, :-1]\n",
        "        y_test = data.iloc[:, -1]\n",
        "\n",
        "        # Load the model\n",
        "        with open(self.model_file, 'rb') as f:\n",
        "            self.model = pickle.load(f)\n",
        "\n",
        "        # Evaluate the model on the test set\n",
        "        y_pred = self.model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        return accuracy\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict the target values for the given features X.\n",
        "\n",
        "        Parameters:\n",
        "        X (array-like): The features to predict the target values.\n",
        "\n",
        "        Returns:\n",
        "        array: The predicted target values.\n",
        "        \"\"\"\n",
        "        # Load the model\n",
        "        with open(self.model_file, 'rb') as f:\n",
        "            self.model = pickle.load(f)\n",
        "\n",
        "        # Predict the target values\n",
        "        y_pred = self.model.predict(X)\n",
        "        return y_pred"
      ],
      "metadata": {
        "id": "33YpBlONC3nm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 創建Model類的一個實例\n",
        "model = Model()\n",
        "\n",
        "# 使用訓練數據訓練模型\n",
        "model.train('train_output.csv')\n",
        "\n",
        "# 使用測試數據評估模型\n",
        "accuracy = model.evaluate('test_output.csv')\n",
        "print('Test Accuracy:', accuracy)\n",
        "\n",
        "# 預測新數據的目標值\n",
        "import numpy as np\n",
        "X_new = np.array([[5.1, 3.5, 1.4, 0.2], [6.7, 3.0, 5.2, 2.3]])\n",
        "y_pred = model.predict(X_new)\n",
        "print('Predicted Target Values:', y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bTEml60C9eA",
        "outputId": "c7728c3b-4e02-4c8b-896c-104f05b8d69d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9583333333333334\n",
            "Test Accuracy: 0.9\n",
            "Predicted Target Values: ['Setosa' 'Virginica']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}